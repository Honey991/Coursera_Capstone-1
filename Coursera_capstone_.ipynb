{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>This notebook is only for foursera capstone projecyt</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#!conda install -c conda-forge BeautifulSoup4 --yes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import urllib.request as urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "# specify the url\n",
    "quote_page = 'https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M'\n",
    "# query the website and return the html to the variable ‘page’\n",
    "page = urllib2.urlopen(quote_page)\n",
    "# parse the html using beautiful soup and store in variable `soup`\n",
    "soup = BeautifulSoup(page, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Scrap data with the use beautifulsoup library</b>\n",
    "<br>save all the data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table = soup.findall(\"table\",{'class':'wikitable sortable jquery-tablesorter'})\n",
    "import re\n",
    "\n",
    "tag = soup.find_all(\"div\", class_=\"mw-parser-output\")\n",
    "table = tag[0].find_all('table')[0]\n",
    "list_Postcode = []\n",
    "list_Borough = []\n",
    "list_Neighbourhood = []\n",
    "count = 0\n",
    "columns_=[]\n",
    "#len(soup.find_all(\"div\", class_=\"mw-parser-output\"))\n",
    "for tr in table.find_all('tbody')[0].find_all('tr'):       \n",
    "    if count >= 1:\n",
    "        td = tr.find_all('td')\n",
    "        list_Postcode.append(re.sub(r'(\\n)','',td[0].get_text()))\n",
    "        list_Borough.append(re.sub(r'(\\n)','',td[1].get_text()))\n",
    "        list_Neighbourhood.append(re.sub(r'(\\n)','',td[2].get_text()))\n",
    "    else:\n",
    "        th = tr.find_all('th')\n",
    "        columns_ = [re.sub(r'(\\n)','',th[0].get_text()),re.sub(r'(\\n)','',th[1].get_text()),re.sub(r'(\\n)','',th[2].get_text())]\n",
    "    count = count+1   \n",
    "#count\n",
    "\n",
    "list1 =list(zip(list_Postcode,list_Borough,list_Neighbourhood))\n",
    "df_uspostcode =pd.DataFrame(list1,  index =np.arange(len(list1)) ,columns = columns_)\n",
    "df_uspostcode = df_uspostcode.groupby(['Postcode','Borough']).agg(', '.join).reset_index()\n",
    "df_uspostcode.loc[df_uspostcode['Neighbourhood']=='Not assigned','Neighbourhood'] = df_uspostcode['Borough']\n",
    "df_uspostcode.drop(df_uspostcode[df_uspostcode['Borough'] == 'Not assigned'].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save data into a csv file after editinf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uspostcode.to_csv('canada_postcode.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_uspostcode.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
